<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification | yuyu</title><meta name="author" content="yuyu"><meta name="copyright" content="yuyu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="⭐论文信息   文献类型：会议论文(CCFB)   发表刊物：MICCAI   发表时间：2024   发表单位：纽约州立大学石溪分校   1.1 拟解决的科学问题✨ 本论文旨在解决Transformer在医学图像分类任务中的应用问题，主要解决了Transformer在医学图像分类任务中特征提取不佳和不能很好地传播有效的信息的问题。✨ 本文属于医学图像分类领域，我还将其归为多尺度融">
<meta property="og:type" content="article">
<meta property="og:title" content="【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification">
<meta property="og:url" content="http://example.com/2025/02/28/post2/index.html">
<meta property="og:site_name" content="yuyu">
<meta property="og:description" content="⭐论文信息   文献类型：会议论文(CCFB)   发表刊物：MICCAI   发表时间：2024   发表单位：纽约州立大学石溪分校   1.1 拟解决的科学问题✨ 本论文旨在解决Transformer在医学图像分类任务中的应用问题，主要解决了Transformer在医学图像分类任务中特征提取不佳和不能很好地传播有效的信息的问题。✨ 本文属于医学图像分类领域，我还将其归为多尺度融">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pica.zhimg.com/v2-fa99c36ab8d889eb688fd3b67b4fc448_1440w.jpg">
<meta property="article:published_time" content="2025-02-27T16:49:17.000Z">
<meta property="article:modified_time" content="2025-03-02T10:22:17.395Z">
<meta property="article:author" content="yuyu">
<meta property="article:tag" content="医学图像分类">
<meta property="article:tag" content="Transformer">
<meta property="article:tag" content="特征提取">
<meta property="article:tag" content="多尺度融合">
<meta property="article:tag" content="局部全局特征融合">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pica.zhimg.com/v2-fa99c36ab8d889eb688fd3b67b4fc448_1440w.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification",
  "url": "http://example.com/2025/02/28/post2/",
  "image": "https://pica.zhimg.com/v2-fa99c36ab8d889eb688fd3b67b4fc448_1440w.jpg",
  "datePublished": "2025-02-27T16:49:17.000Z",
  "dateModified": "2025-03-02T10:22:17.395Z",
  "author": [
    {
      "@type": "Person",
      "name": "yuyu",
      "url": "http://example.com/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/v.png"><link rel="canonical" href="http://example.com/2025/02/28/post2/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="web_bg" style="background-image: url(https://pic3.zhimg.com/v2-226e577e525f24d3e228737bbd0664a6_r.jpg);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/yu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">3</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://faculty.ustc.edu.cn/IPlab/zh_CN/more/655343/jsjjgd/index.htm"><i class="fa-fw fas fa-flask"></i><span> 实验室</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 档案</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://pica.zhimg.com/v2-fa99c36ab8d889eb688fd3b67b4fc448_1440w.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="https://img0.baidu.com/it/u=3750635231,1396466790&amp;fm=253&amp;fmt=auto&amp;app=120&amp;f=JPEG?w=800&amp;h=800" alt="Logo"><span class="site-name">yuyu</span></a><a class="nav-page-title" href="/"><span class="site-name">【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://faculty.ustc.edu.cn/IPlab/zh_CN/more/655343/jsjjgd/index.htm"><i class="fa-fw fas fa-flask"></i><span> 实验室</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 档案</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-02-27T16:49:17.000Z" title="发表于 2025-02-28 00:49:17">2025-02-28</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-03-02T10:22:17.395Z" title="更新于 2025-03-02 18:22:17">2025-03-02</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><figure style="text-align:center;">
    <img src="/sucai/lunwen2/lunwen2.png" style="width: 80%; height: auto;">
</figure>

<h2 id="⭐论文信息"><a href="#⭐论文信息" class="headerlink" title="⭐论文信息"></a>⭐论文信息</h2><div style="display: flex; flex-wrap: wrap;">
  <div style="width: 50%; padding: 10px; font-weight: bold;">文献类型：会议论文(CCFB)</div>
  <div style="width: 50%; padding: 10px; font-weight: bold;">发表刊物：MICCAI</div>
  <div style="width: 50%; padding: 10px; font-weight: bold;">发表时间：2024</div>
  <div style="width: 50%; padding: 10px; font-weight: bold;">发表单位：纽约州立大学石溪分校</div>
</div>

<h3 id="1-1-拟解决的科学问题"><a href="#1-1-拟解决的科学问题" class="headerlink" title="1.1 拟解决的科学问题"></a>1.1 拟解决的科学问题</h3><p>✨ 本论文旨在解决Transformer在医学图像分类任务中的应用问题，主要解决了Transformer在医学图像分类任务中<strong>特征提取不佳</strong>和<strong>不能很好地传播有效的信息</strong>的问题。<br>✨ 本文属于<span class="highlight-text"><strong>医学图像分类</strong></span>领域，我还将其归为<span class="highlight-text"><strong>多尺度融合</strong>领域，具体涉及到<span class="highlight-text"><strong>局部全局特征融合</strong></span>领域。</p>
<h2 id="⭐论文背景"><a href="#⭐论文背景" class="headerlink" title="⭐论文背景"></a>⭐论文背景</h2><h3 id="2-1-基本背景和前提技术"><a href="#2-1-基本背景和前提技术" class="headerlink" title="2.1 基本背景和前提技术"></a>2.1 基本背景和前提技术</h3><p>✨ <strong>多尺度融合</strong>：多尺度融合是指将不同尺度的特征进行融合，以提高特征的表达能力，在图像特征提取中，多尺度融合常表明图像的不同分辨率的特征融合，例如在CNN中设计的多尺度卷积核，卷积核的大小不同，意味着卷积核能够提取不同尺度的特征：越小的卷积核提取的是细节特征，越大的卷积核提取的是全局特征，如何将这些各种尺度的特征融合起来，学术界称之为<span class="highlight-text"><strong>多尺度融合</strong></span>任务。</p>
<p>✨ <strong>Swin-Transformer</strong>：Swin-Transformer是一种图像领域的新的Transformer模型，该模型将图像分成了大量块，每一块都是一个小的图像块，称之为<span class="highlight-normal"><strong>Patch</strong></span>，传统的视觉transformer模型会直接<strong>将每个Patch和其他Patch计算注意力分数</strong>，然而考虑到计算效率，Swin-Transfomer再将若干的Patch组成一个窗口，也称之为<span class="highlight-normal"><strong>Window</strong></span>，然后再计算每个<strong>窗内Patch和其他Patch的注意力分数</strong>，之后再设计了一个<span class="highlight-normal"><strong>Shift Window</strong></span>的机制，将Patch的位置信息传递给下一层，具体来说，就是将窗口进行滑动，<strong>使得原本不在同一个窗口内的Patch，滑窗后可能在同一个窗口内</strong>，这样就能够保证Patch之间的位置信息能够传递到下一层。这种设计共使用<strong>俩次</strong>注意力机制，一次是<strong>window Patch内注意力</strong>，一次是<strong>shift window Patch注意力</strong>，这种设计使得Swin-Transformer在图像分类任务中取得了非常好的效果。</p>
<h3 id="2-2-挖坑"><a href="#2-2-挖坑" class="headerlink" title="2.2 挖坑"></a>2.2 挖坑</h3><p>✨ 医学图像分类面临疾病内在复杂性的挑战，比如病变区域小，对比度低，与其他区域相似。<br><span class="bbox">However, medical image classification presents challenges due to the intrinsic complexities of diseases, such as very small infected regions (e.g., nodules in chest x-rays), poor contrast between background and infected regions, and diseased areas resembling other normal areas (e.g., diseased black dots on skin similar to mole marks).</span><br>好像就挖了这一个坑？？</p>
<h3 id="2-3-相关工作"><a href="#2-3-相关工作" class="headerlink" title="2.3 相关工作"></a>2.3 相关工作</h3><p>✨ <strong>CNN</strong>： 尽管CNN在图像特征提取任务中取得了巨大成功，但是CNN在医学图像分类任务中存在一些问题，CNN内在缺陷是<strong>难以整合上下文信息，只关注局部区域，难以对全局特征进行整合</strong>。<br><span class="bbox">Despite their remarkable performance, CNNs have inherent limitations. For instance, each convolutional kernel can only focus on a sub-region of the input image due to its inherent inductive biases, complicating the extraction of global contextual information crucial for medical image classification.</span></p>
<p>✨ <strong>Inception networks</strong>：为了解决CNN的困境，Inception网络提出了多尺度卷积核，以提取不同尺度的特征，但是Inception网络容易遇到<strong>梯度消失和信息丢失</strong>的问题。<br><span class="bbox">To tackle this challenge, researchers introduced Inception networks [17], capable of extracting multi-scale information. However, these networks encounter issues such as vanishing gradients and information loss from earlier layers.</span></p>
<p>✨ <strong>Residual networks &amp; DenseNets</strong>：为了解决梯度消失和信息丢失的问题，ResNet和DenseNet提出了<strong>残差连接</strong>和<strong>密集连接</strong>，但是这些网络仍然存在一些问题，<strong>它没办法将注意力关注到重要的区域</strong>。<br><span class="bbox">Although these networks capture information from earlier layers, they may not enable the model to focus attentions on specific regions essential for medical image classification, as they lack attention mechanisms to emphasize important features.</span></p>
<p>✨ <strong>Transformer</strong>：基于Transformer的视觉模型，如ViT和Swin-Transformer，尽管它们可以<strong>有效利用上下文信息</strong>，但是它们<strong>难以有效整合局部特征与全局特征</strong>，还可能遇到<strong>信息丢失</strong>的问题。<br><span class="bbox">Recently, Transformer-based approaches with self-attention mechanisms have been developed for image recognition, such as Vision Transformers (ViT) [3], capable of capturing better contextual information compared to CNNs [6,10]. These methods partition the input image into non-overlapping patches and utilize a window (a collection of patches) for self-attention computation. To further enhance contextual information extraction, researchers introduced Swin Transformers [12]. These networks employ sequentially connected two transformer blocks with different window strategies for computing self-attention. However, these networks do not fully capture information at local and global levels and suffer from information loss from earlier layers.</span></p>
<h3 id="2-4-一句话总结技术"><a href="#2-4-一句话总结技术" class="headerlink" title="2.4 一句话总结技术"></a>2.4 一句话总结技术</h3><p>为了解决这些限制，我们引入了 Med-Former，这是一种基于transformer的方法，擅长增强在本地和全局级别提取重要信息的能力，同时缓解在网络的各个层中传播重要信息期间的信息丢失问题。<br><span class="bbox">To address these limitations, we introduce Med-Former, a transformer-based approach adept at enhancing the capability of extracting essential information at both local and global levels while mitigating issues of information loss during the propagation of essential information throughout various layers of the network.</span></p>
<p><span class="yubox">本文并没有一句话具体介绍技术，它其实是提到了自己的主要贡献来达到介绍技术的作用。</span></p>
<h3 id="2-5-主要贡献"><a href="#2-5-主要贡献" class="headerlink" title="2.5 主要贡献"></a>2.5 主要贡献</h3><p>✨ 我们提出了一个 <sapn class="highlight-text"><strong>Local-Global Transformer(LGT)</strong></sapn>模块，它受swin-transformer的启发，设计了<strong>双重尺度的注意力机制</strong>，即shift window attention的窗长和patch attention的窗长不一致，这样可以使得模型能够更好地整合局部和全局特征。<br>✨ 我们提出了一个 <sapn class="highlight-text"><strong>Spatial Attention Fusion(SAF)</strong></sapn>模块，它用于传递<strong>早期层的特征</strong>到网络中，这种设计可以使得模型能够更好地传播重要信息。（以免<strong>信息丢失</strong>）<br>✨ 我们的方法在各种分类任务中取得了先进的性能。</p>
<h2 id="⭐论文方法"><a href="#⭐论文方法" class="headerlink" title="⭐论文方法"></a>⭐论文方法</h2><figure style="text-align:center;">
    <img src="/sucai/lunwen2/l2_f2.png" style="width: 100%; height: auto;">
</figure>



<style>
    .highlight-text {
      background-color: #f0f8ff;         /* 设置背景色 */
      border-radius: 4px;                /* 设置圆角 */
      padding: 0 5px;                    /* 设置内边距，确保文本不与边框贴得太紧 */
      box-shadow: 1px 1px 3px rgba(0, 0, 0, 0.1);  /* 添加轻微的阴影 */
      border: 2px solidrgb(0, 98, 133);         /* 添加边缘线，颜色为浅灰色，宽度为 2px */
    }
  </style>

  <style>
    .highlight-normal {
      background-color: #fff8dc;         /* 设置浅黄色背景色 */
      border-radius: 4px;                /* 设置圆角 */
      padding: 0 5px;                    /* 设置内边距，确保文本不与边框贴得太紧 */
      box-shadow: 1px 1px 3px rgba(0, 0, 0, 0.1);  /* 添加轻微的阴影 */
      border: 1px solid #f0e68c;         /* 添加浅黄色边缘线，颜色为浅黄色，宽度为 2px */
    }
  </style>

  <style>
    .bbox {
      background-color: #f0f8ff;        /* 设置背景色为浅黄色 */
      border-radius: 8px;               /* 设置圆角 */
      padding: 10px;                    /* 设置内边距 */
      box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1); /* 添加轻微的阴影 */
      border: 2px solidrgb(126, 230, 206);        /* 设置浅黄色边框 */
      display: block;                   /* 确保框体显示为块元素，独占一行 */
      margin-top: 10px;                 /* 给框体添加顶部间距 */
      font-family: "Times New Roman", Times, serif; /* 设置字体为 Times New Roman */
    }
  </style>


  <style>
    .yubox {
      background-color:rgb(164, 234, 218);        /* 设置背景色为浅黄色 */
      border-radius: 8px;               /* 设置圆角 */
      padding: 10px;                    /* 设置内边距 */
      box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1); /* 添加轻微的阴影 */
      border: 2px solidrgb(126, 230, 206);        /* 设置浅黄色边框 */
      display: block;                   /* 确保框体显示为块元素，独占一行 */
      margin-top: 10px;                 /* 给框体添加顶部间距 */
    }
  </style></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">yuyu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2025/02/28/post2/">http://example.com/2025/02/28/post2/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://example.com" target="_blank">yuyu</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/">医学图像分类</a><a class="post-meta__tags" href="/tags/Transformer/">Transformer</a><a class="post-meta__tags" href="/tags/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/">特征提取</a><a class="post-meta__tags" href="/tags/%E5%A4%9A%E5%B0%BA%E5%BA%A6%E8%9E%8D%E5%90%88/">多尺度融合</a><a class="post-meta__tags" href="/tags/%E5%B1%80%E9%83%A8%E5%85%A8%E5%B1%80%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88/">局部全局特征融合</a></div><div class="post-share"><div class="social-share" data-image="https://pica.zhimg.com/v2-fa99c36ab8d889eb688fd3b67b4fc448_1440w.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related full-width" href="/2025/02/21/post1/" title="【论文阅读】：Large Loss Matters in Weakly Supervised Multi-Label Classification"><img class="cover" src="https://pica.zhimg.com/v2-f71d85e2562138561950f98bea051964_1440w.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">【论文阅读】：Large Loss Matters in Weakly Supervised Multi-Label Classification</div></div><div class="info-2"><div class="info-item-1"> ⭐论文信息   文献类型：会议论文(CCFA)   发表刊物：CVPR   发表时间：2022   发表单位：首尔国立大学   1.1 拟解决的科学问题✨ 本论文旨在解决多标签数据集中标签部分遗漏的问题。✨ 本文属于 弱监督学习 领域。具体属于 弱标签学习 领域或 弱监督多标签学习（WSML） 领域。 ⭐论文背景2.1 基本背景✨ 弱监督多标签学习（WSML）In a WSML setting, labels are given as a form of partial label, which means only a small amount of categories is annotated per image. This setting reflects the recently released large-scale multi-label datasets [12,19] which provide only partial label.  ✨...</div></div></div></a></nav><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div><div class="comment-switch"><span class="first-comment">Valine</span><span id="switch-btn"></span><span class="second-comment">Gitalk</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/yu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">yuyu</div><div class="author-info-description">欢迎来到yuyu的个人博客</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">3</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/gityuyuhub" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:2743342512@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%AD%90%E8%AE%BA%E6%96%87%E4%BF%A1%E6%81%AF"><span class="toc-number">1.</span> <span class="toc-text">⭐论文信息</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E6%8B%9F%E8%A7%A3%E5%86%B3%E7%9A%84%E7%A7%91%E5%AD%A6%E9%97%AE%E9%A2%98"><span class="toc-number">1.1.</span> <span class="toc-text">1.1 拟解决的科学问题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%AD%90%E8%AE%BA%E6%96%87%E8%83%8C%E6%99%AF"><span class="toc-number">2.</span> <span class="toc-text">⭐论文背景</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E5%9F%BA%E6%9C%AC%E8%83%8C%E6%99%AF%E5%92%8C%E5%89%8D%E6%8F%90%E6%8A%80%E6%9C%AF"><span class="toc-number">2.1.</span> <span class="toc-text">2.1 基本背景和前提技术</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E6%8C%96%E5%9D%91"><span class="toc-number">2.2.</span> <span class="toc-text">2.2 挖坑</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C"><span class="toc-number">2.3.</span> <span class="toc-text">2.3 相关工作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-%E4%B8%80%E5%8F%A5%E8%AF%9D%E6%80%BB%E7%BB%93%E6%8A%80%E6%9C%AF"><span class="toc-number">2.4.</span> <span class="toc-text">2.4 一句话总结技术</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-5-%E4%B8%BB%E8%A6%81%E8%B4%A1%E7%8C%AE"><span class="toc-number">2.5.</span> <span class="toc-text">2.5 主要贡献</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%AD%90%E8%AE%BA%E6%96%87%E6%96%B9%E6%B3%95"><span class="toc-number">3.</span> <span class="toc-text">⭐论文方法</span></a></li></ol></div></div><div class="card-widget card-post-series"><div class="item-headline"><i class="fa-solid fa-layer-group"></i><span>系列文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/02/28/post2/" title="【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification"><img src="https://pica.zhimg.com/v2-fa99c36ab8d889eb688fd3b67b4fc448_1440w.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification"></a><div class="content"><a class="title" href="/2025/02/28/post2/" title="【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification">【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification</a><time datetime="2025-02-27T16:49:17.000Z" title="发表于 2025-02-28 00:49:17">2025-02-28</time></div></div></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/02/28/post2/" title="【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification"><img src="https://pica.zhimg.com/v2-fa99c36ab8d889eb688fd3b67b4fc448_1440w.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification"/></a><div class="content"><a class="title" href="/2025/02/28/post2/" title="【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification">【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification</a><time datetime="2025-02-27T16:49:17.000Z" title="发表于 2025-02-28 00:49:17">2025-02-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/02/21/post1/" title="【论文阅读】：Large Loss Matters in Weakly Supervised Multi-Label Classification"><img src="https://pica.zhimg.com/v2-f71d85e2562138561950f98bea051964_1440w.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】：Large Loss Matters in Weakly Supervised Multi-Label Classification"/></a><div class="content"><a class="title" href="/2025/02/21/post1/" title="【论文阅读】：Large Loss Matters in Weakly Supervised Multi-Label Classification">【论文阅读】：Large Loss Matters in Weakly Supervised Multi-Label Classification</a><time datetime="2025-02-20T16:54:42.000Z" title="发表于 2025-02-21 00:54:42">2025-02-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/02/19/hello-world/" title="Hello World"><img src="https://picx.zhimg.com/v2-701cefaa24bd17aa93e71ae007e23f03_1440w.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hello World"/></a><div class="content"><a class="title" href="/2025/02/19/hello-world/" title="Hello World">Hello World</a><time datetime="2025-02-19T13:26:24.682Z" title="发表于 2025-02-19 21:26:24">2025-02-19</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(https://pica.zhimg.com/v2-fa99c36ab8d889eb688fd3b67b4fc448_1440w.jpg);"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By yuyu</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.3</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const initValine = (el, path) => {
    if (isShuoshuo) {
      window.shuoshuoComment.destroyValine = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }

    const valineConfig = {
      el: '#vcomment',
      appId: '',
      appKey: '',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      visitor: false,
      ...option,
      path: isShuoshuo ? path : (option && option.path) || window.location.pathname
    }

    new Valine(valineConfig)
  }

  const loadValine = async (el, path) => {
    if (typeof Valine === 'function') {
      initValine(el, path)
    } else {
      await btf.getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js')
      initValine(el, path)
    }
  }

  if (isShuoshuo) {
    'Valine' === 'Valine'
      ? window.shuoshuoComment = { loadComment: loadValine }
      : window.loadOtherComment = loadValine
    return
  }

  if ('Valine' === 'Valine' || !true) {
    if (true) btf.loadComment(document.getElementById('vcomment'),loadValine)
    else setTimeout(loadValine, 0)
  } else {
    window.loadOtherComment = loadValine
  }
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const commentCount = n => {
    const isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
    if (isCommentCount) {
      isCommentCount.textContent= n
    }
  }

  const initGitalk = (el, path) => {
    if (isShuoshuo) {
      window.shuoshuoComment.destroyGitalk = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }

    const gitalk = new Gitalk({
      clientID: '',
      clientSecret: '',
      repo: '',
      owner: '',
      admin: [''],
      updateCountCallback: commentCount,
      ...option,
      id: isShuoshuo ? path : (option && option.id) || 'b1bbe7be598640a4b6f13dd213fbe783'
    })

    gitalk.render('gitalk-container')
  }

  const loadGitalk = async(el, path) => {
    if (typeof Gitalk === 'function') initGitalk(el, path)
    else {
      await btf.getCSS('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css')
      await btf.getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js')
      initGitalk(el, path)
    }
  }

  if (isShuoshuo) {
    'Valine' === 'Gitalk'
      ? window.shuoshuoComment = { loadComment: loadGitalk }
      : window.loadOtherComment = loadGitalk
    return
  }

  if ('Valine' === 'Gitalk' || !true) {
    if (true) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
    else loadGitalk()
  } else {
    window.loadOtherComment = loadGitalk
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>