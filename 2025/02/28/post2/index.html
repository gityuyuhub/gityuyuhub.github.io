<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification | yuyu</title><meta name="author" content="yuyu"><meta name="copyright" content="yuyu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="⭐论文信息   文献类型：会议论文(CCFB)   发表刊物：MICCAI   发表时间：2024   发表单位：纽约州立大学石溪分校   1.1 拟解决的科学问题✨ 本论文旨在解决Transformer在医学图像分类任务中的应用问题，主要解决了Transformer在医学图像分类任务中特征提取不佳和不能很好地传播有效的信息的问题。✨ 本文属于医学图像分类领域，我还将其归为多尺度融">
<meta property="og:type" content="article">
<meta property="og:title" content="【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification">
<meta property="og:url" content="http://example.com/2025/02/28/post2/index.html">
<meta property="og:site_name" content="yuyu">
<meta property="og:description" content="⭐论文信息   文献类型：会议论文(CCFB)   发表刊物：MICCAI   发表时间：2024   发表单位：纽约州立大学石溪分校   1.1 拟解决的科学问题✨ 本论文旨在解决Transformer在医学图像分类任务中的应用问题，主要解决了Transformer在医学图像分类任务中特征提取不佳和不能很好地传播有效的信息的问题。✨ 本文属于医学图像分类领域，我还将其归为多尺度融">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pica.zhimg.com/v2-fa99c36ab8d889eb688fd3b67b4fc448_1440w.jpg">
<meta property="article:published_time" content="2025-02-27T16:49:17.000Z">
<meta property="article:modified_time" content="2025-03-02T16:46:03.660Z">
<meta property="article:author" content="yuyu">
<meta property="article:tag" content="医学图像分类">
<meta property="article:tag" content="Transformer">
<meta property="article:tag" content="特征提取">
<meta property="article:tag" content="多尺度融合">
<meta property="article:tag" content="局部全局特征融合">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pica.zhimg.com/v2-fa99c36ab8d889eb688fd3b67b4fc448_1440w.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification",
  "url": "http://example.com/2025/02/28/post2/",
  "image": "https://pica.zhimg.com/v2-fa99c36ab8d889eb688fd3b67b4fc448_1440w.jpg",
  "datePublished": "2025-02-27T16:49:17.000Z",
  "dateModified": "2025-03-02T16:46:03.660Z",
  "author": [
    {
      "@type": "Person",
      "name": "yuyu",
      "url": "http://example.com/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/v.png"><link rel="canonical" href="http://example.com/2025/02/28/post2/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="web_bg" style="background-image: url(https://pic3.zhimg.com/v2-226e577e525f24d3e228737bbd0664a6_r.jpg);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/yu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">4</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://faculty.ustc.edu.cn/IPlab/zh_CN/more/655343/jsjjgd/index.htm"><i class="fa-fw fas fa-flask"></i><span> 实验室</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 档案</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://pica.zhimg.com/v2-fa99c36ab8d889eb688fd3b67b4fc448_1440w.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="https://img0.baidu.com/it/u=3750635231,1396466790&amp;fm=253&amp;fmt=auto&amp;app=120&amp;f=JPEG?w=800&amp;h=800" alt="Logo"><span class="site-name">yuyu</span></a><a class="nav-page-title" href="/"><span class="site-name">【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://faculty.ustc.edu.cn/IPlab/zh_CN/more/655343/jsjjgd/index.htm"><i class="fa-fw fas fa-flask"></i><span> 实验室</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 档案</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-02-27T16:49:17.000Z" title="发表于 2025-02-28 00:49:17">2025-02-28</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-03-02T16:46:03.660Z" title="更新于 2025-03-03 00:46:03">2025-03-03</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><figure style="text-align:center;">
    <img src="/sucai/lunwen2/lunwen2.png" style="width: 80%; height: auto;">
</figure>

<h2 id="⭐论文信息"><a href="#⭐论文信息" class="headerlink" title="⭐论文信息"></a>⭐论文信息</h2><div style="display: flex; flex-wrap: wrap;">
  <div style="width: 50%; padding: 10px; font-weight: bold;">文献类型：会议论文(CCFB)</div>
  <div style="width: 50%; padding: 10px; font-weight: bold;">发表刊物：MICCAI</div>
  <div style="width: 50%; padding: 10px; font-weight: bold;">发表时间：2024</div>
  <div style="width: 50%; padding: 10px; font-weight: bold;">发表单位：纽约州立大学石溪分校</div>
</div>

<h3 id="1-1-拟解决的科学问题"><a href="#1-1-拟解决的科学问题" class="headerlink" title="1.1 拟解决的科学问题"></a>1.1 拟解决的科学问题</h3><p>✨ 本论文旨在解决Transformer在医学图像分类任务中的应用问题，主要解决了Transformer在医学图像分类任务中<strong>特征提取不佳</strong>和<strong>不能很好地传播有效的信息</strong>的问题。<br>✨ 本文属于<span class="highlight-text"><strong>医学图像分类</strong></span>领域，我还将其归为<span class="highlight-text"><strong>多尺度融合</strong></span>领域，具体涉及到<span class="highlight-text"><strong>局部全局特征融合</strong></span>领域。</p>
<h2 id="⭐论文背景"><a href="#⭐论文背景" class="headerlink" title="⭐论文背景"></a>⭐论文背景</h2><h3 id="2-1-基本背景和前提技术"><a href="#2-1-基本背景和前提技术" class="headerlink" title="2.1 基本背景和前提技术"></a>2.1 基本背景和前提技术</h3><p>✨ <strong>多尺度融合</strong>：多尺度融合是指将不同尺度的特征进行融合，以提高特征的表达能力，在图像特征提取中，多尺度融合常表明图像的不同分辨率的特征融合，例如在CNN中设计的多尺度卷积核，卷积核的大小不同，意味着卷积核能够提取不同尺度的特征：越小的卷积核提取的是细节特征，越大的卷积核提取的是全局特征，如何将这些各种尺度的特征融合起来，学术界称之为<span class="highlight-text"><strong>多尺度融合</strong></span>任务。</p>
<p>✨ <strong>Swin-Transformer</strong>：Swin-Transformer是一种图像领域的新的Transformer模型，该模型将图像分成了大量块，每一块都是一个小的图像块，称之为<span class="highlight-normal"><strong>Patch</strong></span>，传统的视觉transformer模型会直接<strong>将每个Patch和其他Patch计算注意力分数</strong>，然而考虑到计算效率，Swin-Transfomer再将若干的Patch组成一个窗口，也称之为<span class="highlight-normal"><strong>Window</strong></span>，然后再计算每个<strong>窗内Patch和其他Patch的注意力分数</strong>，之后再设计了一个<span class="highlight-normal"><strong>Shift Window</strong></span>的机制，将Patch的位置信息传递给下一层，具体来说，就是将窗口进行滑动，<strong>使得原本不在同一个窗口内的Patch，滑窗后可能在同一个窗口内</strong>，这样就能够保证Patch之间的位置信息能够传递到下一层。这种设计共使用<strong>俩次</strong>注意力机制，一次是<strong>window Patch内注意力(W-MSA)</strong>，一次是<strong>shift window Patch注意力(SW-MSA)</strong>，这种设计使得Swin-Transformer在图像分类任务中取得了非常好的效果。</p>
<h3 id="2-2-挖坑"><a href="#2-2-挖坑" class="headerlink" title="2.2 挖坑"></a>2.2 挖坑</h3><p>✨ 医学图像分类面临疾病内在复杂性的挑战，比如病变区域小，对比度低，与其他区域相似。<br><span class="bbox">However, medical image classification presents challenges due to the intrinsic complexities of diseases, such as very small infected regions (e.g., nodules in chest x-rays), poor contrast between background and infected regions, and diseased areas resembling other normal areas (e.g., diseased black dots on skin similar to mole marks).</span><br>好像就挖了这一个坑？？</p>
<h3 id="2-3-相关工作"><a href="#2-3-相关工作" class="headerlink" title="2.3 相关工作"></a>2.3 相关工作</h3><p>✨ <strong>CNN</strong>： 尽管CNN在图像特征提取任务中取得了巨大成功，但是CNN在医学图像分类任务中存在一些问题，CNN内在缺陷是<strong>难以整合上下文信息，只关注局部区域，难以对全局特征进行整合</strong>。<br><span class="bbox">Despite their remarkable performance, CNNs have inherent limitations. For instance, each convolutional kernel can only focus on a sub-region of the input image due to its inherent inductive biases, complicating the extraction of global contextual information crucial for medical image classification.</span></p>
<p>✨ <strong>Inception networks</strong>：为了解决CNN的困境，Inception网络提出了多尺度卷积核，以提取不同尺度的特征，但是Inception网络容易遇到<strong>梯度消失和信息丢失</strong>的问题。<br><span class="bbox">To tackle this challenge, researchers introduced Inception networks [17], capable of extracting multi-scale information. However, these networks encounter issues such as vanishing gradients and information loss from earlier layers.</span></p>
<p>✨ <strong>Residual networks &amp; DenseNets</strong>：为了解决梯度消失和信息丢失的问题，ResNet和DenseNet提出了<strong>残差连接</strong>和<strong>密集连接</strong>，但是这些网络仍然存在一些问题，<strong>它没办法将注意力关注到重要的区域</strong>。<br><span class="bbox">Although these networks capture information from earlier layers, they may not enable the model to focus attentions on specific regions essential for medical image classification, as they lack attention mechanisms to emphasize important features.</span></p>
<p>✨ <strong>Transformer</strong>：基于Transformer的视觉模型，如ViT和Swin-Transformer，尽管它们可以<strong>有效利用上下文信息</strong>，但是它们<strong>难以有效整合局部特征与全局特征</strong>，还可能遇到<strong>信息丢失</strong>的问题。<br><span class="bbox">Recently, Transformer-based approaches with self-attention mechanisms have been developed for image recognition, such as Vision Transformers (ViT) [3], capable of capturing better contextual information compared to CNNs [6,10]. These methods partition the input image into non-overlapping patches and utilize a window (a collection of patches) for self-attention computation. To further enhance contextual information extraction, researchers introduced Swin Transformers [12]. These networks employ sequentially connected two transformer blocks with different window strategies for computing self-attention. However, these networks do not fully capture information at local and global levels and suffer from information loss from earlier layers.</span></p>
<h3 id="2-4-一句话总结技术"><a href="#2-4-一句话总结技术" class="headerlink" title="2.4 一句话总结技术"></a>2.4 一句话总结技术</h3><p>为了解决这些限制，我们引入了 Med-Former，这是一种基于transformer的方法，擅长增强在本地和全局级别提取重要信息的能力，同时缓解在网络的各个层中传播重要信息期间的信息丢失问题。<br><span class="bbox">To address these limitations, we introduce Med-Former, a transformer-based approach adept at enhancing the capability of extracting essential information at both local and global levels while mitigating issues of information loss during the propagation of essential information throughout various layers of the network.</span></p>
<p><span class="yubox">本文并没有一句话具体介绍技术，它其实是提到了自己的主要贡献来达到介绍技术的作用。</span></p>
<h3 id="2-5-主要贡献"><a href="#2-5-主要贡献" class="headerlink" title="2.5 主要贡献"></a>2.5 主要贡献</h3><p>✨ 我们提出了一个 <sapn class="highlight-text"><strong>Local-Global Transformer(LGT)</strong></sapn>模块，它受swin-transformer的启发，设计了<strong>双重尺度的注意力机制</strong>，即<strong>W-MSA</strong>的窗长和<strong>SW-MSA</strong>的中分别设定了窗长不一致的特征提取，这样可以使得模型能够更好地整合局部和全局特征。<br>✨ 我们提出了一个 <sapn class="highlight-text"><strong>Spatial Attention Fusion(SAF)</strong></sapn>模块，它用于传递<strong>早期层的特征</strong>到网络中，这种设计可以使得模型能够更好地传播重要信息。（以免<strong>信息丢失</strong>）<br>✨ 我们的方法在各种分类任务中取得了先进的性能。</p>
<h2 id="⭐论文方法"><a href="#⭐论文方法" class="headerlink" title="⭐论文方法"></a>⭐论文方法</h2><figure style="text-align:center;">
    <img src="/sucai/lunwen2/l2_f2.png" style="width: 100%; height: auto;">
</figure>

<p>本文使用的技术架构与<span class="highlight-text"><strong>Swin-Transformer</strong></span>相似，并且中间很多模块直接也是使用的Swin-Transformer的模块，但是本文提出了两个新的模块，一个是<strong>Local-Global Transformer(LGT)</strong>，另一个是<strong>Spatial Attention Fusion(SAF)</strong>。此架构分为三个部分：<span class="highlight-normal"><strong>编码阶段（Encoding phase）</strong></span>和<span class="highlight-normal"><strong>0阶段（Stage 0）</strong></span>和<span class="highlight-normal"><strong>阶段1（Stage 1）</strong></span>。笔者大致梳理了一下这个架构，具体如下：</p>
<p>假设输入图像形状是$H \times W \times 3$，它将首先进行<span class="highlight-text"><strong>Patch partitioning</strong></span>，这是swin-transfomer的模块，它负责对图像分块，即分成若干个patch，假如要分成$N \times N$个patch，那么每个patch的大小就是$\frac{H}{N} \times \frac{W}{N}$，因此输出形状即$\frac{H}{N} \times \frac{W}{N} \times (N \times N \times 3)$。</p>
<p>进入<span class="highlight-normal"><strong>编码阶段</strong></span>，这些patch将会被送入到<span class="highlight-text"><strong>Linear Embedding</strong></span>模块中，这里只是把$(N \times N \times 3)$嵌入到$d$维度中。即输出形状是$\frac{H}{N} \times \frac{W}{N} \times d$，再经过<span class="highlight-text"><strong>LGT</strong></span>模块进行全局局部特征提取后形状不变，仍然是$\frac{H}{N} \times \frac{W}{N} \times d$。</p>
<p>接着进入<span class="highlight-normal"><strong>阶段0</strong></span>，首先进行<span class="highlight-text"><strong>Patch Merging</strong></span>下采样模块，这也是swin-transformer的模块，它输入的特征图。进行<strong>通道数加倍，空间尺寸减半</strong>的操作，即输出形状是$\frac{H}{2N} \times \frac{W}{2N} \times 2d$，然后经过<span class="highlight-text"><strong>LGT</strong></span>模块，形状不变，仍然是$\frac{H}{2N} \times \frac{W}{2N} \times 2d$。最后输入到<span class="highlight-text"><strong>SAF</strong></span>模块，<strong>整合编码层的输出特征和当前特征</strong>，形状不变，仍然是$\frac{H}{2N} \times \frac{W}{2N} \times 2d$。</p>
<p>最后进入K次<span class="highlight-normal"><strong>阶段1</strong></span>，首先进行<strong>Patch Merging</strong>下采样模块，输出的特征图形状是$\frac{H}{4N} \times \frac{W}{4N} \times 4d$，然后经过<span class="highlight-text"><strong>LGT</strong></span>模块，形状不变，仍然是$\frac{H}{4N} \times \frac{W}{4N} \times 4d$。最后输入到<span class="highlight-text"><strong>SAF</strong></span>模块，<strong>整合编码层的输出特征和上一个stage的特征</strong>，形状不变，仍然是$\frac{H}{4N} \times \frac{W}{4N} \times 4d$。经过K次<span class="highlight-normal">阶段1</span>后，输出的特征图形状是$\frac{H}{N\times 2^{K+1}} \times \frac{W}{N\times 2^{K+1}} \times 2^{K+1}d$。</p>
<p><span class="yubox">笔者：这里有很多模块，想要真正理解好，得先明白<strong>swin-transformer</strong>的内容，例如其中的<strong>Patch Merging</strong>和<strong>Patch Partitioning</strong>模块，这些模块都是swin-transformer的模块。<strong>Patch Partitioning</strong>为了将图像分块，达到transformer的输入要求，<strong>Patch Merging</strong>则是为了下采样，其类似于CNN中的<strong>卷积层+池化层</strong>。</span></p>
<h3 id="3-1-Local-Global-Transformer-LGT-模块"><a href="#3-1-Local-Global-Transformer-LGT-模块" class="headerlink" title="3.1 Local-Global Transformer(LGT)模块"></a>3.1 Local-Global Transformer(LGT)模块</h3><figure style="text-align:center;">
    <img src="/sucai/lunwen2/l2_f3.png" style="width: 50%; height: auto;">
</figure>

<p>本图中仍然还是优化了Swin-Transformer的模块，图的左半部分<strong>Block $l$</strong>使用的就是swin-transformer提出的<strong>W-MSA（窗注意力机制）</strong>，右半部分<strong>Block $l+1$</strong>使用的是<strong>SW-MSA（滑窗注意力机制）</strong>。</p>
<p>以左图为例，$W_m-MSA$和$SW_n-MSA$就是指利用窗长为$m$和$n$的注意力机制，$G_p$表示的是<strong>全局特征路径</strong>，$L_p$表示的是<strong>局部特征路径</strong>，因此要求$G_p$的窗长应该大于$L_p$的窗长，即<strong>$\color{red}m&gt;n$</strong>。</p>
<p>此外需要注意的是，<strong>$W_m-MSA$和$SW_n-MSA$都是注意力机制，无论窗长是多少，输出的形状都保持不变，与输入形状相同</strong>，因此可以直接对$G_p$和$L_p$进行<strong>特征加和</strong>，这样就能够很好地整合局部和全局特征，而左半部分的输出即右半部分的输入。</p>
<p><strong>LN</strong>表示层归一化层，<strong>MLP</strong>表示多层感知机，LGT中有多处<strong>残差连接</strong>，例如注意力机制的输出和LN输入，以及MLP的输出和LN输入，这样可以使得模型更加稳定，防止记忆丢失。</p>
<h3 id="3-2-Spatial-Attention-Fusion-SAF-模块"><a href="#3-2-Spatial-Attention-Fusion-SAF-模块" class="headerlink" title="3.2 Spatial Attention Fusion(SAF)模块"></a>3.2 Spatial Attention Fusion(SAF)模块</h3><figure style="text-align:center;">
    <img src="/sucai/lunwen2/l2_f4.png" style="width: 20%; height: auto;">
</figure>

<p>这个简单的模块就是作者所提的空间注意力融合模块，它的作用是整合<strong>上次阶段的输出和本阶段的输出</strong>，这样可以使得模型能够更好地传播重要信息，防止信息丢失。<br>它具体接收俩个输入$f_A$和$f_B$，$f_A$表示上阶段的输出，$f_B$表示本阶段的输出，根据前文对技术方案大图的介绍，由于$f_B$相比较$f_A$多经历了一次<span class="highlight-text"><strong>Patch Merging</strong></span>也就是下采样操作，导致形状不匹配。因此对于$f_A$，该模块要求先对它进行<span class="highlight-normal"><strong>Downsample</strong></span>下采样操作使得形状匹配。之后对俩个特征分别进行<span class="highlight"><strong>空间自注意力机制（Spatial Attention）</strong></span>，最后进行<strong>特征融合（Fusion）</strong>。最后输入到下一个阶段。</p>
<p><span class="yubox">原文对模块的介绍很少，甚至都没有解释<strong>Spatial Attention</strong>是怎么计算的，笔者猜测<strong>Spatial Attention</strong>应该是一个现成的即插即用的模块。原文还没有具体介绍<strong>Fusion</strong>操作具体是怎么进行的，那么笔者就直接按照<strong>加和</strong>来理解了。</span></p>
<h2 id="⭐实验设定"><a href="#⭐实验设定" class="headerlink" title="⭐实验设定"></a>⭐实验设定</h2><h3 id="4-1-数据集与实验细节"><a href="#4-1-数据集与实验细节" class="headerlink" title="4.1 数据集与实验细节"></a>4.1 数据集与实验细节</h3><p>本文将该方法运用到三个任务进行评估。任务和使用的数据集如下表：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">任务</th>
<th style="text-align:left">数据集</th>
<th style="text-align:left">后文简称</th>
<th style="text-align:left">评估指标</th>
<th style="text-align:left">图片量（训练/测试）</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">胸部疾病分类</td>
<td style="text-align:left">NIH Chest X-ray14</td>
<td style="text-align:left">Chest X</td>
<td style="text-align:left">AUC</td>
<td style="text-align:left">86524/25596</td>
</tr>
<tr>
<td style="text-align:left">皮损分类</td>
<td style="text-align:left">DermaMNIST</td>
<td style="text-align:left">DM</td>
<td style="text-align:left">ACC</td>
<td style="text-align:left">8010/2005</td>
</tr>
<tr>
<td style="text-align:left">血细胞分类</td>
<td style="text-align:left">BloodMNIST</td>
<td style="text-align:left">BM</td>
<td style="text-align:left">ACC</td>
<td style="text-align:left">13671/3421</td>
</tr>
</tbody>
</table>
</div>
<p>对于这三个数据集，通过交叉验证确定 Med-Former 的阶段数为 K = 3。该模型是通过最小化 400 个 epoch 的 CrossEntropy 损失来训练的，使用批量大小 16 和 0.001 的初始学习率。此外，学习率每 100 个 epoch 衰减 0.1 倍。所有实验均在具有 NVIDIA Tesla V100 GPU 上进行。</p>
<h3 id="4-2-SOTA对比"><a href="#4-2-SOTA对比" class="headerlink" title="4.2 SOTA对比"></a>4.2 SOTA对比</h3><p>进行了俩组实验，实验一是与<strong>基于transformer的方法</strong>进行对比，即与VIT和Swin-Transformer进行对比，实验二是与<strong>SOTA方法</strong>进行对比。实验一的结果如图：</p>
<figure style="text-align:center;">
    <img src="/sucai/lunwen2/l2_f5.png" style="width: 65%; height: auto;">
</figure>

<p>显然，所提方法在三个任务上的性能均优于 VIT 和 Swin-Transformer。第二组实验结果如图：</p>
<figure style="text-align:center;">
    <img src="/sucai/lunwen2/l2_f6.png" style="width: 70%; height: auto;">
</figure>

<p>在这组实验中，Med-Former 在所有任务上均优于 SOTA 方法。</p>
<h3 id="4-3-消融实验"><a href="#4-3-消融实验" class="headerlink" title="4.3 消融实验"></a>4.3 消融实验</h3><p>作者设定了消融实验，主要是验证了<strong>LGT</strong>和<strong>SAF</strong>模块的有效性，实验结果如下：</p>
<figure style="text-align:center;">
    <img src="/sucai/lunwen2/l2_f7.png" style="width: 70%; height: auto;">
</figure>

<p>先看第一行，模型既没有使用<strong>LGT</strong>模块也没有使用<strong>SAF</strong>模块，只使用了<strong>Swin-Transformer</strong>的模块，这是最基础的版本。<br>第二行，模型使用了<strong>Concat</strong>操作来代替<strong>SAF</strong>模块，使用向量连接的手段进行<strong>阶段间特征融合</strong>，可以看到相比于第一行，性能提升，说明<strong>阶段间特征融合</strong>是有效的。<br>第三行，模型使用了<strong>SAF</strong>模块，可以看到相比于第二行，性能提升，说明<strong>SAF</strong>模块是<strong>更有效的阶段间特征融合</strong>方法。</p>
<p>再看第四行，模型使用了<strong>LGT</strong>模块，但不进行阶段间特征融合，可以看到相比于第一行，性能提升，说明<strong>LGT</strong>模块是有效的。<br>最后看第五行，模型使用了<strong>LGT</strong>模块和<strong>Concat</strong>模块，可以看到相比于第四行，性能提升。<br>最后看第六行，模型使用了<strong>LGT</strong>模块和<strong>SAF</strong>模块，也就是本文方法，可以是全部最优的。</p>
<p>文章还提供了<strong>注意力可视化热图</strong>，可以看到<strong>LGT</strong>模块和<strong>SAF</strong>模块的有效性，实验结果如下：</p>
<p><figure style="text-align:center;">
    <img src="/sucai/lunwen2/l2_f8.png" style="width: 80%; height: auto;">
</figure><br>可以看出，加入各个模块的效果，其中我们的方法，可以<strong>精确地关注到重要的区域</strong>，这是其他方法所做不到的。（这个图，不要看框，看背景染色）</p>
<h2 id="⭐笔者总结"><a href="#⭐笔者总结" class="headerlink" title="⭐笔者总结"></a>⭐笔者总结</h2><p>这篇文章提出了一种更加有效的医学图像基于transformer特征提取方法。全文主要是对<strong>Swin-Transformer</strong>的改进，主要是提出了<strong>LGT</strong>和<strong>SAF</strong>模块，这两个模块的作用是<strong>局部全局特征融合</strong>和<strong>阶段间特征融合</strong>。然而感觉作者的语料不太充足，有些模块也没有介绍清楚。</p>
<p>但是本文提到的调整窗大小来进行<strong>多尺度特征融合</strong>确实是一个简单且有效的方案，也告诉我需要学一学swin-transformer的内容。</p>
 <style>
    .highlight-text {
      background-color: #f0f8ff;         /* 设置背景色 */
      border-radius: 4px;                /* 设置圆角 */
      padding: 0 5px;                    /* 设置内边距，确保文本不与边框贴得太紧 */
      box-shadow: 1px 1px 3px rgba(0, 0, 0, 0.1);  /* 添加轻微的阴影 */
      border: 2px solidrgb(0, 98, 133);         /* 添加边缘线，颜色为浅灰色，宽度为 2px */
    }
  </style>

  <style>
    .highlight-normal {
      background-color: #fff8dc;         /* 设置浅黄色背景色 */
      border-radius: 4px;                /* 设置圆角 */
      padding: 0 5px;                    /* 设置内边距，确保文本不与边框贴得太紧 */
      box-shadow: 1px 1px 3px rgba(0, 0, 0, 0.1);  /* 添加轻微的阴影 */
      border: 1px solid #f0e68c;         /* 添加浅黄色边缘线，颜色为浅黄色，宽度为 2px */
    }
  </style>

  <style>
    .bbox {
      background-color: #f0f8ff;        /* 设置背景色为浅黄色 */
      border-radius: 8px;               /* 设置圆角 */
      padding: 10px;                    /* 设置内边距 */
      box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1); /* 添加轻微的阴影 */
      border: 2px solidrgb(126, 230, 206);        /* 设置浅黄色边框 */
      display: block;                   /* 确保框体显示为块元素，独占一行 */
      margin-top: 10px;                 /* 给框体添加顶部间距 */
      font-family: "Times New Roman", Times, serif; /* 设置字体为 Times New Roman */
    }
  </style>


  <style>
    .yubox {
      background-color:rgb(229, 234, 204);        /* 设置背景色为浅黄色 */
      border-radius: 8px;               /* 设置圆角 */
      padding: 10px;                    /* 设置内边距 */
      box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1); /* 添加轻微的阴影 */
      border: 2px solidrgb(126, 230, 206);        /* 设置浅黄色边框 */
      display: block;                   /* 确保框体显示为块元素，独占一行 */
      margin-top: 10px;                 /* 给框体添加顶部间距 */
    }
  </style></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">yuyu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2025/02/28/post2/">http://example.com/2025/02/28/post2/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://example.com" target="_blank">yuyu</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB/">医学图像分类</a><a class="post-meta__tags" href="/tags/Transformer/">Transformer</a><a class="post-meta__tags" href="/tags/%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/">特征提取</a><a class="post-meta__tags" href="/tags/%E5%A4%9A%E5%B0%BA%E5%BA%A6%E8%9E%8D%E5%90%88/">多尺度融合</a><a class="post-meta__tags" href="/tags/%E5%B1%80%E9%83%A8%E5%85%A8%E5%B1%80%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88/">局部全局特征融合</a></div><div class="post-share"><div class="social-share" data-image="https://pica.zhimg.com/v2-fa99c36ab8d889eb688fd3b67b4fc448_1440w.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/02/21/post1/" title="【论文阅读】：Large Loss Matters in Weakly Supervised Multi-Label Classification"><img class="cover" src="https://pic1.zhimg.com/v2-c49dda70ee82730ec6f2c46f58df84e4_r.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">【论文阅读】：Large Loss Matters in Weakly Supervised Multi-Label Classification</div></div><div class="info-2"><div class="info-item-1"> ⭐论文信息   文献类型：会议论文(CCFA)   发表刊物：CVPR   发表时间：2022   发表单位：首尔国立大学   1.1 拟解决的科学问题✨ 本论文旨在解决多标签数据集中标签部分遗漏的问题。✨ 本文属于 弱监督学习 领域。具体属于 弱标签学习 领域或 弱监督多标签学习（WSML） 领域。 ⭐论文背景2.1 基本背景✨ 弱监督多标签学习（WSML）In a WSML setting, labels are given as a form of partial label, which means only a small amount of categories is annotated per image. This setting reflects the recently released large-scale multi-label datasets [12,19] which provide only partial label.  ✨...</div></div></div></a><a class="pagination-related" href="/2025/03/04/post3/" title="【技术篇】transformer解析"><img class="cover" src="https://pica.zhimg.com/v2-f71d85e2562138561950f98bea051964_1440w.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">【技术篇】transformer解析</div></div><div class="info-2"><div class="info-item-1">    ...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/03/04/post3/" title="【技术篇】transformer解析"><img class="cover" src="https://pica.zhimg.com/v2-f71d85e2562138561950f98bea051964_1440w.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-03-04</div><div class="info-item-2">【技术篇】transformer解析</div></div><div class="info-2"><div class="info-item-1">    ...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/yu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">yuyu</div><div class="author-info-description">欢迎来到yuyu的个人博客</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">4</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">9</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/gityuyuhub" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:2743342512@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">This is my Blog</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%AD%90%E8%AE%BA%E6%96%87%E4%BF%A1%E6%81%AF"><span class="toc-number">1.</span> <span class="toc-text">⭐论文信息</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E6%8B%9F%E8%A7%A3%E5%86%B3%E7%9A%84%E7%A7%91%E5%AD%A6%E9%97%AE%E9%A2%98"><span class="toc-number">1.1.</span> <span class="toc-text">1.1 拟解决的科学问题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%AD%90%E8%AE%BA%E6%96%87%E8%83%8C%E6%99%AF"><span class="toc-number">2.</span> <span class="toc-text">⭐论文背景</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E5%9F%BA%E6%9C%AC%E8%83%8C%E6%99%AF%E5%92%8C%E5%89%8D%E6%8F%90%E6%8A%80%E6%9C%AF"><span class="toc-number">2.1.</span> <span class="toc-text">2.1 基本背景和前提技术</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E6%8C%96%E5%9D%91"><span class="toc-number">2.2.</span> <span class="toc-text">2.2 挖坑</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C"><span class="toc-number">2.3.</span> <span class="toc-text">2.3 相关工作</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-%E4%B8%80%E5%8F%A5%E8%AF%9D%E6%80%BB%E7%BB%93%E6%8A%80%E6%9C%AF"><span class="toc-number">2.4.</span> <span class="toc-text">2.4 一句话总结技术</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-5-%E4%B8%BB%E8%A6%81%E8%B4%A1%E7%8C%AE"><span class="toc-number">2.5.</span> <span class="toc-text">2.5 主要贡献</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%AD%90%E8%AE%BA%E6%96%87%E6%96%B9%E6%B3%95"><span class="toc-number">3.</span> <span class="toc-text">⭐论文方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-Local-Global-Transformer-LGT-%E6%A8%A1%E5%9D%97"><span class="toc-number">3.1.</span> <span class="toc-text">3.1 Local-Global Transformer(LGT)模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-Spatial-Attention-Fusion-SAF-%E6%A8%A1%E5%9D%97"><span class="toc-number">3.2.</span> <span class="toc-text">3.2 Spatial Attention Fusion(SAF)模块</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%AD%90%E5%AE%9E%E9%AA%8C%E8%AE%BE%E5%AE%9A"><span class="toc-number">4.</span> <span class="toc-text">⭐实验设定</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8E%E5%AE%9E%E9%AA%8C%E7%BB%86%E8%8A%82"><span class="toc-number">4.1.</span> <span class="toc-text">4.1 数据集与实验细节</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-SOTA%E5%AF%B9%E6%AF%94"><span class="toc-number">4.2.</span> <span class="toc-text">4.2 SOTA对比</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-%E6%B6%88%E8%9E%8D%E5%AE%9E%E9%AA%8C"><span class="toc-number">4.3.</span> <span class="toc-text">4.3 消融实验</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%AD%90%E7%AC%94%E8%80%85%E6%80%BB%E7%BB%93"><span class="toc-number">5.</span> <span class="toc-text">⭐笔者总结</span></a></li></ol></div></div><div class="card-widget card-post-series"><div class="item-headline"><i class="fa-solid fa-layer-group"></i><span>系列文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/02/28/post2/" title="【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification"><img src="https://pica.zhimg.com/v2-fa99c36ab8d889eb688fd3b67b4fc448_1440w.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification"></a><div class="content"><a class="title" href="/2025/02/28/post2/" title="【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification">【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification</a><time datetime="2025-02-27T16:49:17.000Z" title="发表于 2025-02-28 00:49:17">2025-02-28</time></div></div></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/03/04/post3/" title="【技术篇】transformer解析"><img src="https://pica.zhimg.com/v2-f71d85e2562138561950f98bea051964_1440w.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【技术篇】transformer解析"/></a><div class="content"><a class="title" href="/2025/03/04/post3/" title="【技术篇】transformer解析">【技术篇】transformer解析</a><time datetime="2025-03-03T16:58:17.000Z" title="发表于 2025-03-04 00:58:17">2025-03-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/02/28/post2/" title="【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification"><img src="https://pica.zhimg.com/v2-fa99c36ab8d889eb688fd3b67b4fc448_1440w.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification"/></a><div class="content"><a class="title" href="/2025/02/28/post2/" title="【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification">【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification</a><time datetime="2025-02-27T16:49:17.000Z" title="发表于 2025-02-28 00:49:17">2025-02-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/02/21/post1/" title="【论文阅读】：Large Loss Matters in Weakly Supervised Multi-Label Classification"><img src="https://pic1.zhimg.com/v2-c49dda70ee82730ec6f2c46f58df84e4_r.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】：Large Loss Matters in Weakly Supervised Multi-Label Classification"/></a><div class="content"><a class="title" href="/2025/02/21/post1/" title="【论文阅读】：Large Loss Matters in Weakly Supervised Multi-Label Classification">【论文阅读】：Large Loss Matters in Weakly Supervised Multi-Label Classification</a><time datetime="2025-02-20T16:54:42.000Z" title="发表于 2025-02-21 00:54:42">2025-02-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/02/19/hello-world/" title="Hello World"><img src="https://pic1.zhimg.com/v2-ffa731613043c6236cf6fd5dd003aa46_r.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="Hello World"/></a><div class="content"><a class="title" href="/2025/02/19/hello-world/" title="Hello World">Hello World</a><time datetime="2025-02-19T13:26:24.682Z" title="发表于 2025-02-19 21:26:24">2025-02-19</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(https://pica.zhimg.com/v2-fa99c36ab8d889eb688fd3b67b4fc448_1440w.jpg);"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By yuyu</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.3</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const commentCount = n => {
    const isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
    if (isCommentCount) {
      isCommentCount.textContent= n
    }
  }

  const initGitalk = (el, path) => {
    if (isShuoshuo) {
      window.shuoshuoComment.destroyGitalk = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }

    const gitalk = new Gitalk({
      clientID: 'Ov23lienmr7axdYseqeC',
      clientSecret: 'b7f1b4e555108e1113715eb05f7527c6d1ad667d',
      repo: 'gityuyuhub.github.io',
      owner: 'gityuyuhub',
      admin: ['gityuyuhub'],
      updateCountCallback: commentCount,
      ...option,
      id: isShuoshuo ? path : (option && option.id) || 'b1bbe7be598640a4b6f13dd213fbe783'
    })

    gitalk.render('gitalk-container')
  }

  const loadGitalk = async(el, path) => {
    if (typeof Gitalk === 'function') initGitalk(el, path)
    else {
      await btf.getCSS('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css')
      await btf.getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js')
      initGitalk(el, path)
    }
  }

  if (isShuoshuo) {
    'Gitalk' === 'Gitalk'
      ? window.shuoshuoComment = { loadComment: loadGitalk }
      : window.loadOtherComment = loadGitalk
    return
  }

  if ('Gitalk' === 'Gitalk' || !true) {
    if (true) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
    else loadGitalk()
  } else {
    window.loadOtherComment = loadGitalk
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>