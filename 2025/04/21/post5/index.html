<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>【论文阅读】：Med-2E3：A 2D-Enhanced 3D Medical Multimodal Large Language Model | yuyu</title><meta name="author" content="yuyu"><meta name="copyright" content="yuyu"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="⭐论文信息   文献类型：预印本 arxiv    发表刊物：arxiv   发表时间：2024   发表单位：清华大学   1.1 拟解决的科学问题✨ 本论文旨在构建一个适用于3D医学影像理解的多模态大模型，主要解决三维特征提取问题。✨ 本文属于医学大模型、多模态大模型、3D特征提取、局部全局特征融合等领域。 ⭐论文背景2.1 摘要写作解读 第一句【挖坑一】：介绍3D医学影像分析">
<meta property="og:type" content="article">
<meta property="og:title" content="【论文阅读】：Med-2E3：A 2D-Enhanced 3D Medical Multimodal Large Language Model">
<meta property="og:url" content="http://example.com/2025/04/21/post5/index.html">
<meta property="og:site_name" content="yuyu">
<meta property="og:description" content="⭐论文信息   文献类型：预印本 arxiv    发表刊物：arxiv   发表时间：2024   发表单位：清华大学   1.1 拟解决的科学问题✨ 本论文旨在构建一个适用于3D医学影像理解的多模态大模型，主要解决三维特征提取问题。✨ 本文属于医学大模型、多模态大模型、3D特征提取、局部全局特征融合等领域。 ⭐论文背景2.1 摘要写作解读 第一句【挖坑一】：介绍3D医学影像分析">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pic1.zhimg.com/v2-ffa731613043c6236cf6fd5dd003aa46_r.jpg">
<meta property="article:published_time" content="2025-04-20T17:57:17.000Z">
<meta property="article:modified_time" content="2025-04-25T17:46:43.748Z">
<meta property="article:author" content="yuyu">
<meta property="article:tag" content="局部全局特征融合">
<meta property="article:tag" content="医学大模型">
<meta property="article:tag" content="多模态大模型">
<meta property="article:tag" content="3D特征提取">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pic1.zhimg.com/v2-ffa731613043c6236cf6fd5dd003aa46_r.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "【论文阅读】：Med-2E3：A 2D-Enhanced 3D Medical Multimodal Large Language Model",
  "url": "http://example.com/2025/04/21/post5/",
  "image": "https://pic1.zhimg.com/v2-ffa731613043c6236cf6fd5dd003aa46_r.jpg",
  "datePublished": "2025-04-20T17:57:17.000Z",
  "dateModified": "2025-04-25T17:46:43.748Z",
  "author": [
    {
      "@type": "Person",
      "name": "yuyu",
      "url": "http://example.com/"
    }
  ]
}</script><link rel="shortcut icon" href="/img/v.png"><link rel="canonical" href="http://example.com/2025/04/21/post5/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":true},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '【论文阅读】：Med-2E3：A 2D-Enhanced 3D Medical Multimodal Large Language Model',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 7.3.0"></head><body><div id="web_bg" style="background-image: url(https://pic3.zhimg.com/v2-226e577e525f24d3e228737bbd0664a6_r.jpg);"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/yu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">6</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">12</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://faculty.ustc.edu.cn/IPlab/zh_CN/more/655343/jsjjgd/index.htm"><i class="fa-fw fas fa-flask"></i><span> 实验室</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 档案</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="/my-daily/"><i class="fa-fw fas fa-calendar-day"></i><span> 我的日常</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(https://pic1.zhimg.com/v2-ffa731613043c6236cf6fd5dd003aa46_r.jpg);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src="https://img0.baidu.com/it/u=3750635231,1396466790&amp;fm=253&amp;fmt=auto&amp;app=120&amp;f=JPEG?w=800&amp;h=800" alt="Logo"><span class="site-name">yuyu</span></a><a class="nav-page-title" href="/"><span class="site-name">【论文阅读】：Med-2E3：A 2D-Enhanced 3D Medical Multimodal Large Language Model</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" target="_blank" rel="noopener" href="https://faculty.ustc.edu.cn/IPlab/zh_CN/more/655343/jsjjgd/index.htm"><i class="fa-fw fas fa-flask"></i><span> 实验室</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 档案</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友情链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page" href="/my-daily/"><i class="fa-fw fas fa-calendar-day"></i><span> 我的日常</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">【论文阅读】：Med-2E3：A 2D-Enhanced 3D Medical Multimodal Large Language Model</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-04-20T17:57:17.000Z" title="发表于 2025-04-21 01:57:17">2025-04-21</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-04-25T17:46:43.748Z" title="更新于 2025-04-26 01:46:43">2025-04-26</time></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><figure style="text-align:center;">
    <img src="/sucai/lunwen3/lunwen3.png" style="width: 85%; height: auto;">
</figure>

<h2 id="⭐论文信息"><a href="#⭐论文信息" class="headerlink" title="⭐论文信息"></a>⭐论文信息</h2><div style="display: flex; flex-wrap: wrap;">
  <div style="width: 50%; padding: 10px; font-weight: bold;">文献类型：预印本 arxiv </div>
  <div style="width: 50%; padding: 10px; font-weight: bold;">发表刊物：arxiv</div>
  <div style="width: 50%; padding: 10px; font-weight: bold;">发表时间：2024</div>
  <div style="width: 50%; padding: 10px; font-weight: bold;">发表单位：清华大学</div>
</div>

<h3 id="1-1-拟解决的科学问题"><a href="#1-1-拟解决的科学问题" class="headerlink" title="1.1 拟解决的科学问题"></a>1.1 拟解决的科学问题</h3><p>✨ 本论文旨在构建一个适用于3D医学影像理解的多模态大模型，主要解决<strong>三维特征提取</strong>问题。<br>✨ 本文属于<sapn class="highlight-text"><strong>医学大模型</strong></sapn>、<sapn class="highlight-text"><strong>多模态大模型</strong></sapn>、<sapn class="highlight-text"><strong>3D特征提取</strong></sapn>、<sapn class="highlight-text"><strong>局部全局特征融合</strong></sapn>等领域。</p>
<h2 id="⭐论文背景"><a href="#⭐论文背景" class="headerlink" title="⭐论文背景"></a>⭐论文背景</h2><h3 id="2-1-摘要写作解读"><a href="#2-1-摘要写作解读" class="headerlink" title="2.1 摘要写作解读"></a>2.1 摘要写作解读</h3><ul>
<li><strong>第一句</strong>【<strong>挖坑一</strong>】：介绍3D医学影像分析的重要性，但在不同医学场景的通用性有限，现有的<strong>任务特定</strong>模型变得越来越不足。</li>
<li><strong>第二句</strong>【<strong>填坑一</strong>】：多模态大模型（MLLMs）为这个挑战提供了一个有前途的解决方案。</li>
<li><strong>第三句</strong>【<strong>挖坑二</strong>】：然而，现有的MLLMs在提取3维医学图像丰富、分层的信息方面仍然不足。</li>
<li><strong>第四句</strong>【介绍本文方法】：受放射科医生同时关注3D结构和2D切片内容的实践启发，我们提出了、<sapn class="highlight-text"><strong>Med-2E3</strong></sapn>，一个新的多模态大模型，同时利用了2D编码器和3D编码器。</li>
<li><strong>第五句</strong>【<strong>填坑二</strong>】：为了更有效地聚合2D切片特征，我们设计了文本引导的切片间评分模块（<sapn class="highlight-text"><strong>TG-IS</strong></sapn>）对每个2D切片进行注意力打分。</li>
<li><strong>第六句</strong>【强调创新点】：据我们所知，Med-2E3是第一个同时集成3D和2D功能的医学影像分析的MLLM。</li>
<li><strong>第七句</strong>【实验性能介绍】：在大规模开源3D医学多模态基准测试上表现好……</li>
<li><strong>第八句</strong>【代码】：文章接收后会开源代码和模型。</li>
</ul>
<h3 id="2-2-挖坑"><a href="#2-2-挖坑" class="headerlink" title="2.2 挖坑"></a>2.2 挖坑</h3><p>✨<strong>任务特定</strong>的模型很难处理复杂的多模态医学图像分析任务。</p>
<p><sapn class="bbox">However, traditional task-specific models [12, 36, 52] often face challenges such as limited data and small model sizes, which make it difficult to handle complex multimodal tasks.
</sapn><br>填坑：LLMs（<strong>大模型</strong>）在解决复杂的医疗多模态任务方面显示出广阔的潜力，为弥合模型研究和临床应用之间的差距提供了前景。<br><span class="bbox">These models have shown promising potential in addressing complex medical multimodal tasks, offering the prospect of bridging the gap between model research and clinical application.
</span></p>
<p>✨现有的医学MLLMs聚焦于2维图像，而很少研究3维图像…(中间作者在介绍为什么很少研究3维图像，因为没有现成可以用的3维图像编码器)3维图像编码器需要从头开始训练，表征能力有限。</p>
<p><sapn class="bbox">However, existing medical MLLMs primarily focus on 2D medical images, with limited research on 3D medical MLLMs [9, 10, 13, 19].
</sapn><br><span class="bbox">As a result, 3D encoders must be trained from scratch on 3D medical images, which limits their representational capacity.
</span></p>
<h3 id="2-3-相关工作"><a href="#2-3-相关工作" class="headerlink" title="2.3 相关工作"></a>2.3 相关工作</h3><h4 id="3D医学图像分析"><a href="#3D医学图像分析" class="headerlink" title="3D医学图像分析"></a>3D医学图像分析</h4><p><strong>LLM</strong>出现之前：都是<strong>任务特定</strong>的模型，主要是面向医学图像分割或分类。</p>
<p><strong>LLM</strong>出现之后：研究人员已经开始收集大规模 3D 医疗多模态数据集，用于3D医学多模态大模型训练和评估。长期以来，从 3D 图像中提取特征一直是 3D 医学图像分析中的一个挑战。以前的研究通常遵循以下两种方法之一。</p>
<p>【<strong>直接提取3D图像特征</strong>】：这种流派主张直接对3D图像进行提取特征，然而，由于3D医学图像的独特模态，这些编码器需要从头开始对3D数据进行训练，并且在捕获切片内细节方面往往无法达到通用域编码器的性能水平。<br>【<strong>2D逐切片聚合3D特征</strong>】：另一种方法涉及逐个切片提取特征，在聚合之前独立处理每个2D切片。虽然这种方法允许使用根据3D数据微调的预训练2D编码器，但它很难对3D图像中的切片间关系进行建模。</p>
<h4 id="医学多模态大模型"><a href="#医学多模态大模型" class="headerlink" title="医学多模态大模型"></a>医学多模态大模型</h4><p>医学MLLM的早期研究主要集中在2D医学图像上，而对3D医学图像的研究相对较少。</p>
<p>现有的3D医疗MLLM主要依靠3D编码器进行特征提取。这种单编码器设计在3D医疗多模态任务中无法实现与2D MLLM在2D多模态任务中相同的卓越性能。</p>
<h3 id="2-4-一句话总结技术"><a href="#2-4-一句话总结技术" class="headerlink" title="2.4 一句话总结技术"></a>2.4 一句话总结技术</h3><p>我们提出了 Med-2E3，这是一种用于 3D 医学图像分析的新型MLLM，集成了3D和2D编码器。为了更有效地聚合2D特征，我们设计了一个文本引导的切片间 （TG-IS） 评分模块，该模块根据切片内容和任务说明对每个2D切片的注意力进行评分。</p>
<p><span class="bbox">we propose Med-2E3, a novel MLLM for 3D medical image analysis that integrates 3D and 2D encoders. To aggregate 2D features more effectively, we design a Text-Guided Inter-Slice (TG-IS) scoring module, which scores the attention of each 2D slice based on slice contents and task instructions.</span></p>
<h3 id="2-5-主要贡献"><a href="#2-5-主要贡献" class="headerlink" title="2.5 主要贡献"></a>2.5 主要贡献</h3><p>✨ 我们提出了<strong>Med-2E3</strong>，一种用于3D医学图像分析的新型MLLM。据我们所知，<span class="highlight-text"><strong>Med-2E3</strong></span>是第一款集成3D和2D编码器的3D医疗MLLM。<br>✨ 我们设计了一个文本引导切片间（<span class="highlight-text"><strong>TG-IS</strong></span>） 评分模块，以模拟放射科医生在3D医学图像分析中使用的注意力机制。该模块根据切片内容和任务说明对每个切片的注意力进行评分。<br>✨ 我们提出的 Med-2E3 在最大的3D医疗多模态基准测试中实现了最先进的性能。</p>
<h2 id="⭐论文方法"><a href="#⭐论文方法" class="headerlink" title="⭐论文方法"></a>⭐论文方法</h2><figure style="text-align:center;">
  <img src="/sucai/lunwen3/l3_f1.png" style="width: 100%; height: auto;">
</figure>

<p><span class="highlight-text"><strong>Med-2E3</strong></span>的输入有俩个，即3D医学影像$\boldsymbol{x_I}$和对应的文本问题$\boldsymbol{x_T}$，模型的输出是一个文本答案$\boldsymbol{x_R}$。模型的整体架构如上图所示。他们的形状即如下：</p>
<ul>
<li>3D医学影像$\boldsymbol{x_I}=\{\boldsymbol{x_I}^j\}$：$N \times H \times W$：$N$表示切片数，$W$表示宽度，$H$表示高度。$\color{red}\{ \}$表示集合。</li>
<li>第j切片2D图像$\boldsymbol{x_I}^j$：$H \times W$</li>
<li>文本问题$\boldsymbol{x_T}$：文本。</li>
<li>文本答案$\boldsymbol{x_R}$：文本。</li>
</ul>
<p>接下来，<span class="highlight-text"><strong>Med-2E3</strong></span>将分别对3维图像使用3D编码块、对逐个2维图像使用2D编码块（一个编码块包含一个编码器+连接器）得到对应特征表示$\boldsymbol{z_{3D}}$和$\{\boldsymbol{z_{2D}^j}\}$。<span style="color: red;">尽管作者说$\boldsymbol{z_{3D}}$是一个一维的特征向量，在技术路线图也画成一维的形式，然而我多次推敲探究，按我的理解，其应该是一个二维矩阵，且形状是$L \times D$，这个形状也是作者自己写的，似乎与自己说的“一维的特征向量”的描述有所矛盾？因此按照我的理解，图中$\boldsymbol{z_{3D}}$中每一个色块不能当做一个标量值，而应该理解为一个长度为D的向量</span>。因此，得到的特征表示$\boldsymbol{z_{3D}}$和$\{\boldsymbol{z_{2D}^j}\}$的形状分别是：</p>
<ul>
<li>3D编码块输出$\boldsymbol{z_{3D}}$：$L_2 \times D$：$L_2$表示3D编码器的输出长度，$D$表示提取后的特征维度。</li>
<li>2D编码块输出$\{\boldsymbol{z_{2D}^j}\}$：$N \times L’ \times D$：$L’$表示2D编码器的输出长度。</li>
<li>第$j$切片2D编码块输出$\boldsymbol{z_{2D}^j}$：$L_2 \times D$</li>
</ul>
<p>接着，初步提取的俩种特征将送入到<sapn class="highlight-text"><strong>TG-IS</strong></sapn>模块中进行切片间评分，得到每个切片的注意力分数，并利用该注意力分数聚合2D特征并与初步的3D特征连接。这些2D增强的3D特征以及文本特征由LLM处理以生成响应。</p>
<h3 id="3-1-3D和2D编码块"><a href="#3-1-3D和2D编码块" class="headerlink" title="3.1 3D和2D编码块"></a>3.1 3D和2D编码块</h3><figure style="text-align:center;">
  <img src="/sucai/lunwen3/l3_f2.png" style="width: 100%; height: auto;">
</figure>

<p>论文并没有详细介绍3D和2D编码块，经过我的研究，他们的工作机理应该如下描述：<br>【<strong>3D编码块</strong>】：<br>3D编码块包括一个<strong>冻结参数</strong>的<span class="highlight-text"><strong>3D编码器</strong></span>和一个<strong>可训练的</strong><span class="highlight-text"><strong>3D连接器</strong></span>。<span class="highlight-text"><strong>3D编码器</strong></span>用于提取3D医学图像的特征，连接器用于<strong>下采样（池化）</strong>。3D编码块接收的输入是三维的3D医学图像$\boldsymbol{x_I}$，输出是3D特征（2维）$\boldsymbol{z_{3D}}$。</p>
<p>按照我的理解，本文使用的<span class="highlight-text"><strong>3D编码器</strong></span>是基于VIT的3D编码器，即将3D图像分割成若干个3D块（patch），然后将每个3D块展平为一个向量，最后将这些向量输入到VIT中进行处理。</p>
<figure style="text-align:center;">
  <img src="/sucai/lunwen3/l3_f3.png" style="width: 65%; height: auto;">
</figure>

<p>如上图，<span class="highlight-text"><strong>3D编码器</strong></span>的输入是3D医学图像$\boldsymbol{x_I} \in \mathbb{R}^{N \times H \times W}$，论文使用的3D编码器把该3D图像分割成若干patch，每个patch的大小即$N_1 \times H_1 \times W_1$，然后以patch为单位进行提取特征，简单的说，<strong>对于每一个patch，编码器就会输出一个D维向量表征其特征</strong>。那共有多少个patch呢？显然可以推算到一共有$L_1$个patch，$L_1$的计算公式如下：</p>
<script type="math/tex; mode=display">
L_1 = \frac{N}{N_1} \cdot \frac{H}{H_1} \cdot \frac{W}{W_1}</script><p>接着，经过3D图像编码后，3D编码器会输出一个$L_1 \times D$的矩阵，表示每个patch的特征。接下来，连接器会对该矩阵进行下采样（池化），得到一个$L_2 \times D$的矩阵，$L_2$表示下采样后的长度。下采样的过程可以如图所示：</p>
<figure style="text-align:center;">
  <img src="/sucai/lunwen3/l3_f4.png" style="width: 65%; height: auto;">
</figure>

<p>如上图所示，经过3D编码器后，3D医学图像$\boldsymbol{x_I}$会被分割成$L_1$个patch，输出特征即$L_1 \times D$的矩阵，图中即按照$L_1$个较大的矩阵块，每个较大的矩阵块对应$D$个特征。以<strong>平均池化</strong>为例，连接器会对每个较大的矩阵块进行平均池化，即选取$P \times P \times P$个patch取平均(对应图中的红色框线)，这样每$P \cdot P \cdot P$个patch就会被池化成一个特征，最终得到$L_2$个特征。$L_2$的计算公式如下：</p>
<script type="math/tex; mode=display">
L_2 = \frac{L_1}{P^3}</script><p>最终3D编码块的输出即表示为：</p>
<script type="math/tex; mode=display">
z_{3D} \in \mathbb{R}^{L_2 \times D}, L_2 = \frac{L_1}{P^3} = \frac{N}{N_1} \cdot \frac{H}{H_1} \cdot \frac{W}{W_1} \cdot \frac{1}{P^3}</script><p>【<strong>2D编码块</strong>】：<br>2D编码块包括一个<strong>冻结参数</strong>的<span class="highlight-text"><strong>2D编码器</strong></span>和一个<strong>可训练的</strong><span class="highlight-text"><strong>2D连接器</strong></span>。<span class="highlight-text"><strong>2D编码器</strong></span>用于提取2D医学图像的特征，连接器用于<strong>下采样（池化）</strong>。2D编码块接收的输入是二维的2D医学图像$\boldsymbol{x_I}^j$，输出是2D特征（3维）$\boldsymbol{z_{2D}^j}$。</p>
<p>整个过程如下图所示：</p>
<figure style="text-align:center;">
  <img src="/sucai/lunwen3/l3_f5.png" style="width: 50%; height: auto;">
</figure>

<p>首先经过2D编码器后，每一张2D医学图像$\boldsymbol{x_I}^j$会被分割成$L_1$个patch，输出特征即$L_1 \times D$的矩阵，图中即按照$L_1$个较大的矩阵块，每个较大的矩阵块对应$D$个特征。接着，连接器会对该矩阵进行下采样（池化），最后得到一个$L_2$个特征。$L_2$的计算公式如下：</p>
<script type="math/tex; mode=display">
L_2 = \frac{L_1}{P^2}</script><p>最终每一张图片在2D编码块的输出即表示为：</p>
<script type="math/tex; mode=display">
z_{2D}^j \in \mathbb{R}^{L_2 \times D}, L_2 = \frac{L_1}{P^2} = \frac{H}{H_1} \cdot \frac{W}{W_1} \cdot \frac{1}{P^2} \\</script><p>因此，2D编码块的输出集合为：</p>
<script type="math/tex; mode=display">
\{ z_{2D}^j\} \in \mathbb{R}^{N \times L_2 \times D}</script><p>显然，这是一个三维的矩阵，与3D编码块的输出是一个二维的矩阵不同。</p>
<h3 id="3-1-TG-IS模块"><a href="#3-1-TG-IS模块" class="headerlink" title="3.1 TG-IS模块"></a>3.1 TG-IS模块</h3><p><figure style="text-align:center;">
  <img src="/sucai/lunwen3/l3_f6.png" style="width: 70%; height: auto;">
</figure><br><span class="highlight-text"><strong>TG-IS</strong></span>模块的输入是2D编码块的输出$\{z_{2D}^j\}$和3D编码块的输出$z_{3D}$，输出是每个2D切片的注意力分数$\boldsymbol{s}$。该模块的原理即综合利用初步提取的3D特征$z_{3D}$和2D特征$\{z_{2D}^j\}$，对每个2D切片进行注意力评分。该模块首先将3D特征$z_{3D}$进行<strong>形状转换</strong>（对应图中的<code>split</code>）以将其转换为与2D特征$\{z_{2D}^j\}$同样三维的形状，接着对转换后的3D特征和2D特征进行<strong>拼接</strong>，最后将拼接后的特征与文本特征计算每个2D切片的注意力分数。该模块的输出即为每个2D切片的注意力分数$\boldsymbol{s}$，其形状为$N \times 1$，表示每个2D切片的注意力分数。</p>
<p>【<strong>形状转换</strong>】：<br>由于3D编码块的输出$z_{3D}$是一个二维的矩阵，而2D编码块的输出$\{z_{2D}^j\}$是一个三维的矩阵，因此需要对$z_{3D}$进行形状转换。首先我们知道初步的三维特征形状如下：</p>
<script type="math/tex; mode=display">
z_{3D} \in \mathbb{R}^{L_2 \times D}, L_2 = \frac{L_1}{P^3} = \frac{N}{N_1} \cdot \frac{H}{H_1} \cdot \frac{W}{W_1} \cdot \frac{1}{P^3}</script><p>因此可以通过<code>reshape</code>函数将其转换为下面形状：</p>
<script type="math/tex; mode=display">
(L_2, D) \rightarrow (\frac{N}{N_1\cdot P}, \frac{H}{H_1\cdot P}, \frac{W}{W_1\cdot P}, D)</script><p>接着把第一维度$\frac{N}{N_1\cdot P}$进行复制$N_1\cdot P$次，并且<strong>交叉</strong>拼接起来（怎么交叉的，论文没有描述），即可以得到：</p>
<script type="math/tex; mode=display">
(\frac{N}{N_1\cdot P}, \frac{H}{H_1\cdot P}, \frac{W}{W_1\cdot P}, D) \rightarrow (N, \frac{H}{H_1\cdot P}, \frac{W}{W_1\cdot P}, D)</script><p>最后把第二维度和第三维度合并，即设定$L = \frac{H}{H_1\cdot P} \cdot \frac{W}{W_1\cdot P}$，最终得到的形状为：</p>
<script type="math/tex; mode=display">
z_{3D} \in \mathbb{R}^{N \times L \times D}</script><p>【<strong>拼接</strong>】：<br>经过形状转换后，3D特征$z_{3D}$和2D特征$\{z_{2D}^j\}$的形状分别是$N \times L \times D$和$N \times L_2 \times D$，接下来对这两个特征进行拼接。拼接的方式是将3D特征$z_{3D}$和2D特征$\{z_{2D}^j\}$在第二维度上进行拼接，换句话说即对每一个$z_{3D}^j$和$z_{2D}^j$在第一维度上进行拼接。拼接后的特征形状为$N \times (L + L_2) \times D$，因此获得的特征拼接后的集合形状是$N \times (L + L_2) \times D$。</p>
<p>接下来，<span class="highlight-text"><strong>TG-IS</strong></span>模块会对拼接后的特征进行<strong>平均池化</strong>以消除第二维度$L + L_2$，得到一个$N \times D$的矩阵，整个过程即可描述为：</p>
<script type="math/tex; mode=display">
\boldsymbol{z^j}=\text{AvgPool}(\text{Concat}(z_{3D}^j, z_{2D}^j))</script><p>即第j个切片的综合特征为$\boldsymbol{z^j} \in \mathbb{R}^{D}$，所有切片的综合特征集合为$\{\boldsymbol{z^j}\} \in \mathbb{R}^{N \times D}$。</p>
<p>【<strong>注意力打分</strong>】：<br>什么叫做<strong>文本引导的切片间评分</strong>？简单来说就是模型输入的文本问题不同，模型对每个切片的注意力分数也不同。因此作者即利用文本的特征和每张2D切片的特征进行交互获得每张切片的注意力打分。具体来说，作者使用了一个<strong>文本编码器</strong>来提取文本问题的特征，文本编码器的输出是一个$L_T \times D$的矩阵，$L_T$表示文本编码器的输出长度。</p>
<p>同样地，对文本特征进行平均池化，即可以获得athbb{R}^{D}$的特征。作者通过<strong>点积</strong>来逐个计算文本对每个切片的注意力即：</p>
<script type="math/tex; mode=display">
\boldsymbol{s_r^j} = \text{AvgPool}(\boldsymbol{z_T}) \cdot \boldsymbol{z^j}</script><p>其中$\boldsymbol{s_r^j}$表示第j个切片的注意力分数，$\boldsymbol{z_T}$表示文本特征。最终所有切片的注意力分数集合为$\{\boldsymbol{s_r^j}\} \in \mathbb{R}^{N}$，接下来，按照打分的惯例，用<code>softmax</code>函数对注意力分数进行归一化处理，得到每个切片的注意力分数$\boldsymbol{s}$，即：</p>
<script type="math/tex; mode=display">
\boldsymbol{s} = \text{softmax}(\boldsymbol{s_r^j})</script><p>最终的注意力分数集合为$\boldsymbol{s} \in \mathbb{R}^{N}$。</p>
 <style>
    .highlight-text {
      background-color: #f0f8ff;         /* 设置背景色 */
      border-radius: 4px;                /* 设置圆角 */
      padding: 0 5px;                    /* 设置内边距，确保文本不与边框贴得太紧 */
      box-shadow: 1px 1px 3px rgba(0, 0, 0, 0.1);  /* 添加轻微的阴影 */
      border: 2px solidrgb(0, 98, 133);         /* 添加边缘线，颜色为浅灰色，宽度为 2px */
    }
  </style>

  <style>
    .highlight-normal {
      background-color: #fff8dc;         /* 设置浅黄色背景色 */
      border-radius: 4px;                /* 设置圆角 */
      padding: 0 5px;                    /* 设置内边距，确保文本不与边框贴得太紧 */
      box-shadow: 1px 1px 3px rgba(0, 0, 0, 0.1);  /* 添加轻微的阴影 */
      border: 1px solid #f0e68c;         /* 添加浅黄色边缘线，颜色为浅黄色，宽度为 2px */
    }
  </style>

  <style>
    .bbox {
      background-color: #f0f8ff;        /* 设置背景色为浅黄色 */
      border-radius: 8px;               /* 设置圆角 */
      padding: 10px;                    /* 设置内边距 */
      box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1); /* 添加轻微的阴影 */
      border: 2px solidrgb(126, 230, 206);        /* 设置浅黄色边框 */
      display: block;                   /* 确保框体显示为块元素，独占一行 */
      margin-top: 10px;                 /* 给框体添加顶部间距 */
      font-family: "Times New Roman", Times, serif; /* 设置字体为 Times New Roman */
    }
  </style>


  <style>
    .yubox {
      background-color:rgb(229, 234, 204);        /* 设置背景色为浅黄色 */
      border-radius: 8px;               /* 设置圆角 */
      padding: 10px;                    /* 设置内边距 */
      box-shadow: 0px 4px 6px rgba(0, 0, 0, 0.1); /* 添加轻微的阴影 */
      border: 2px solidrgb(126, 230, 206);        /* 设置浅黄色边框 */
      display: block;                   /* 确保框体显示为块元素，独占一行 */
      margin-top: 10px;                 /* 给框体添加顶部间距 */
    }
  </style></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">yuyu</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2025/04/21/post5/">http://example.com/2025/04/21/post5/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://example.com" target="_blank">yuyu</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%B1%80%E9%83%A8%E5%85%A8%E5%B1%80%E7%89%B9%E5%BE%81%E8%9E%8D%E5%90%88/">局部全局特征融合</a><a class="post-meta__tags" href="/tags/%E5%8C%BB%E5%AD%A6%E5%A4%A7%E6%A8%A1%E5%9E%8B/">医学大模型</a><a class="post-meta__tags" href="/tags/%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B/">多模态大模型</a><a class="post-meta__tags" href="/tags/3D%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96/">3D特征提取</a></div><div class="post-share"><div class="social-share" data-image="https://pic1.zhimg.com/v2-ffa731613043c6236cf6fd5dd003aa46_r.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related full-width" href="/2025/03/16/post4/" title="【技术篇】BCE or CE? 多标签 还是 多分类？"><img class="cover" src="https://picx.zhimg.com/v2-31af717d5ebecb7d19dd56b65383af7f_1440w.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">【技术篇】BCE or CE? 多标签 还是 多分类？</div></div><div class="info-2"><div class="info-item-1">我们在选择损失函数的时候，经常会遇到这样的问题，是选择二元交叉熵（Binary Cross Entropy，BCE），还是选择交叉熵（Cross Entropy，CE）？或许有人简单的认为，二分类问题选择BCE，多分类问题选择CE。那是不是BCE就只能用于二分类问题呢？那么到底有什么细节需要注意呢？本文将为你一一解答。 读完本文你将明白如下：  BCE不仅适用于二分类问题，还适用于多标签问题； CE是不会注意负标签的损失的，而BCE会计算负标签的损失；（BCE不是简单的二元CE） BCE 和 CE 在torch中计算log的底数取e，即ln； CE 在torch中输入接收为logits，而BCE接收为概率值； BCE 和 CE 在torch中还有一个参数reduction，用于控制损失的计算方式； CE 在torch接受的标签是向量而不是矩阵。  ⭐二分类、多分类、多标签二分类问题在正式描述 BCE 和 CE 之前，我们先来了解一下二分类、多分类和多标签的概念。 二分类任务很简单，就是将输入图片分成俩类，即True 和...</div></div></div></a></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><a class="pagination-related" href="/2025/02/28/post2/" title="【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification"><img class="cover" src="https://pic1.zhimg.com/v2-9efa9909ceaf3f5874aa9de8c290610e_1440w.jpg" alt="cover"><div class="info text-center"><div class="info-1"><div class="info-item-1"><i class="far fa-calendar-alt fa-fw"></i> 2025-02-28</div><div class="info-item-2">【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification</div></div><div class="info-2"><div class="info-item-1">        ⭐论文信息   文献类型：会议论文(CCFB)   发表刊物：MICCAI   发表时间：2024   发表单位：纽约州立大学石溪分校   1.1 拟解决的科学问题✨ 本论文旨在解决Transformer在医学图像分类任务中的应用问题，主要解决了Transformer在医学图像分类任务中特征提取不佳和不能很好地传播有效的信息的问题。✨ 本文属于医学图像分类领域，我还将其归为多尺度融合领域，具体涉及到局部全局特征融合领域。 ⭐论文背景2.1 基本背景和前提技术✨ 多尺度融合：多尺度融合是指将不同尺度的特征进行融合，以提高特征的表达能力，在图像特征提取中，多尺度融合常表明图像的不同分辨率的特征融合，例如在CNN中设计的多尺度卷积核，卷积核的大小不同，意味着卷积核能够提取不同尺度的特征：越小的卷积核提取的是细节特征，越大的卷积核提取的是全局特征，如何将这些各种尺度的特征融合起来，学术界称之为多尺度融合任务。 ✨...</div></div></div></a></div></div><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="gitalk-container"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/yu.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">yuyu</div><div class="author-info-description">欢迎来到yuyu的个人博客</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">6</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">12</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">0</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons"><a class="social-icon" href="https://github.com/gityuyuhub" target="_blank" title="Github"><i class="fab fa-github" style="color: #24292e;"></i></a><a class="social-icon" href="mailto:2743342512@qq.com" target="_blank" title="Email"><i class="fas fa-envelope" style="color: #4a7dbe;"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">如你所见，这是我的博客，相信在这些文章中，你会找到你想要的。This is Yuyu</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%AD%90%E8%AE%BA%E6%96%87%E4%BF%A1%E6%81%AF"><span class="toc-number">1.</span> <span class="toc-text">⭐论文信息</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#1-1-%E6%8B%9F%E8%A7%A3%E5%86%B3%E7%9A%84%E7%A7%91%E5%AD%A6%E9%97%AE%E9%A2%98"><span class="toc-number">1.1.</span> <span class="toc-text">1.1 拟解决的科学问题</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%AD%90%E8%AE%BA%E6%96%87%E8%83%8C%E6%99%AF"><span class="toc-number">2.</span> <span class="toc-text">⭐论文背景</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#2-1-%E6%91%98%E8%A6%81%E5%86%99%E4%BD%9C%E8%A7%A3%E8%AF%BB"><span class="toc-number">2.1.</span> <span class="toc-text">2.1 摘要写作解读</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-2-%E6%8C%96%E5%9D%91"><span class="toc-number">2.2.</span> <span class="toc-text">2.2 挖坑</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-3-%E7%9B%B8%E5%85%B3%E5%B7%A5%E4%BD%9C"><span class="toc-number">2.3.</span> <span class="toc-text">2.3 相关工作</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3D%E5%8C%BB%E5%AD%A6%E5%9B%BE%E5%83%8F%E5%88%86%E6%9E%90"><span class="toc-number">2.3.1.</span> <span class="toc-text">3D医学图像分析</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%8C%BB%E5%AD%A6%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B"><span class="toc-number">2.3.2.</span> <span class="toc-text">医学多模态大模型</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-4-%E4%B8%80%E5%8F%A5%E8%AF%9D%E6%80%BB%E7%BB%93%E6%8A%80%E6%9C%AF"><span class="toc-number">2.4.</span> <span class="toc-text">2.4 一句话总结技术</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#2-5-%E4%B8%BB%E8%A6%81%E8%B4%A1%E7%8C%AE"><span class="toc-number">2.5.</span> <span class="toc-text">2.5 主要贡献</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E2%AD%90%E8%AE%BA%E6%96%87%E6%96%B9%E6%B3%95"><span class="toc-number">3.</span> <span class="toc-text">⭐论文方法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-3D%E5%92%8C2D%E7%BC%96%E7%A0%81%E5%9D%97"><span class="toc-number">3.1.</span> <span class="toc-text">3.1 3D和2D编码块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-TG-IS%E6%A8%A1%E5%9D%97"><span class="toc-number">3.2.</span> <span class="toc-text">3.1 TG-IS模块</span></a></li></ol></li></ol></div></div><div class="card-widget card-post-series"><div class="item-headline"><i class="fa-solid fa-layer-group"></i><span>系列文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/04/21/post5/" title="【论文阅读】：Med-2E3：A 2D-Enhanced 3D Medical Multimodal Large Language Model"><img src="https://pic1.zhimg.com/v2-ffa731613043c6236cf6fd5dd003aa46_r.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】：Med-2E3：A 2D-Enhanced 3D Medical Multimodal Large Language Model"></a><div class="content"><a class="title" href="/2025/04/21/post5/" title="【论文阅读】：Med-2E3：A 2D-Enhanced 3D Medical Multimodal Large Language Model">【论文阅读】：Med-2E3：A 2D-Enhanced 3D Medical Multimodal Large Language Model</a><time datetime="2025-04-20T17:57:17.000Z" title="发表于 2025-04-21 01:57:17">2025-04-21</time></div></div></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2025/04/21/post5/" title="【论文阅读】：Med-2E3：A 2D-Enhanced 3D Medical Multimodal Large Language Model"><img src="https://pic1.zhimg.com/v2-ffa731613043c6236cf6fd5dd003aa46_r.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】：Med-2E3：A 2D-Enhanced 3D Medical Multimodal Large Language Model"/></a><div class="content"><a class="title" href="/2025/04/21/post5/" title="【论文阅读】：Med-2E3：A 2D-Enhanced 3D Medical Multimodal Large Language Model">【论文阅读】：Med-2E3：A 2D-Enhanced 3D Medical Multimodal Large Language Model</a><time datetime="2025-04-20T17:57:17.000Z" title="发表于 2025-04-21 01:57:17">2025-04-21</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/03/16/post4/" title="【技术篇】BCE or CE? 多标签 还是 多分类？"><img src="https://picx.zhimg.com/v2-31af717d5ebecb7d19dd56b65383af7f_1440w.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【技术篇】BCE or CE? 多标签 还是 多分类？"/></a><div class="content"><a class="title" href="/2025/03/16/post4/" title="【技术篇】BCE or CE? 多标签 还是 多分类？">【技术篇】BCE or CE? 多标签 还是 多分类？</a><time datetime="2025-03-15T16:54:00.000Z" title="发表于 2025-03-16 00:54:00">2025-03-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/03/04/post3/" title="【技术篇】transformer解析"><img src="https://pica.zhimg.com/v2-fa99c36ab8d889eb688fd3b67b4fc448_1440w.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【技术篇】transformer解析"/></a><div class="content"><a class="title" href="/2025/03/04/post3/" title="【技术篇】transformer解析">【技术篇】transformer解析</a><time datetime="2025-03-03T16:58:17.000Z" title="发表于 2025-03-04 00:58:17">2025-03-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/02/28/post2/" title="【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification"><img src="https://pic1.zhimg.com/v2-9efa9909ceaf3f5874aa9de8c290610e_1440w.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification"/></a><div class="content"><a class="title" href="/2025/02/28/post2/" title="【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification">【论文阅读】：Med-Former： A Transformer-based Architecture for Medical Image Classification</a><time datetime="2025-02-27T16:49:17.000Z" title="发表于 2025-02-28 00:49:17">2025-02-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2025/02/21/post1/" title="【论文阅读】：Large Loss Matters in Weakly Supervised Multi-Label Classification"><img src="https://picx.zhimg.com/v2-701cefaa24bd17aa93e71ae007e23f03_1440w.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【论文阅读】：Large Loss Matters in Weakly Supervised Multi-Label Classification"/></a><div class="content"><a class="title" href="/2025/02/21/post1/" title="【论文阅读】：Large Loss Matters in Weakly Supervised Multi-Label Classification">【论文阅读】：Large Loss Matters in Weakly Supervised Multi-Label Classification</a><time datetime="2025-02-20T16:54:42.000Z" title="发表于 2025-02-21 00:54:42">2025-02-21</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url(https://pic1.zhimg.com/v2-ffa731613043c6236cf6fd5dd003aa46_r.jpg);"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2025 By yuyu</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.3.3</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><div class="js-pjax"><script>(() => {
  const loadMathjax = () => {
    if (!window.MathJax) {
      window.MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']],
          tags: 'none',
        },
        chtml: {
          scale: 1.1
        },
        options: {
          enableMenu: true,
          renderActions: {
            findScript: [10, doc => {
              for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
                const display = !!node.type.match(/; *mode=display/)
                const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
                const text = document.createTextNode('')
                node.parentNode.replaceChild(text, node)
                math.start = {node: text, delim: '', n: 0}
                math.end = {node: text, delim: '', n: 0}
                doc.math.push(math)
              }
            }, '']
          }
        }
      }

      const script = document.createElement('script')
      script.src = 'https://cdn.jsdelivr.net/npm/mathjax/es5/tex-mml-chtml.min.js'
      script.id = 'MathJax-script'
      script.async = true
      document.head.appendChild(script)
    } else {
      MathJax.startup.document.state(0)
      MathJax.texReset()
      MathJax.typesetPromise()
    }
  }

  btf.addGlobalFn('encrypt', loadMathjax, 'mathjax')
  window.pjax ? loadMathjax() : window.addEventListener('load', loadMathjax)
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const commentCount = n => {
    const isCommentCount = document.querySelector('#post-meta .gitalk-comment-count')
    if (isCommentCount) {
      isCommentCount.textContent= n
    }
  }

  const initGitalk = (el, path) => {
    if (isShuoshuo) {
      window.shuoshuoComment.destroyGitalk = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }

    const gitalk = new Gitalk({
      clientID: 'Ov23lienmr7axdYseqeC',
      clientSecret: 'b7f1b4e555108e1113715eb05f7527c6d1ad667d',
      repo: 'gityuyuhub.github.io',
      owner: 'gityuyuhub',
      admin: ['gityuyuhub'],
      updateCountCallback: commentCount,
      ...option,
      id: isShuoshuo ? path : (option && option.id) || '53b2280dd7db35dbc9b44cdabc341cc6'
    })

    gitalk.render('gitalk-container')
  }

  const loadGitalk = async(el, path) => {
    if (typeof Gitalk === 'function') initGitalk(el, path)
    else {
      await btf.getCSS('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.css')
      await btf.getScript('https://cdn.jsdelivr.net/npm/gitalk/dist/gitalk.min.js')
      initGitalk(el, path)
    }
  }

  if (isShuoshuo) {
    'Gitalk' === 'Gitalk'
      ? window.shuoshuoComment = { loadComment: loadGitalk }
      : window.loadOtherComment = loadGitalk
    return
  }

  if ('Gitalk' === 'Gitalk' || !true) {
    if (true) btf.loadComment(document.getElementById('gitalk-container'), loadGitalk)
    else loadGitalk()
  } else {
    window.loadOtherComment = loadGitalk
  }
})()</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>